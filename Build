#!/usr/bin/env bash

set -e      # Exit immediately if any command fails

tests_dir="tests/tests-develop/VMTests/"
output_file="tests/templates/output-uiuck.txt"
expected_passing="tests/passing.expected"
now_passing="tests/passing.lastrun"

if krun --version | grep 'RV' >/dev/null 2>&1; then
    output_file="tests/templates/output-rvk.txt"
fi

progress() { echo "== $@"; }
success()  { echo -e "\e[32m== success: $@\e[0m";
             echo "$@" >> "$now_passing"
           }
failure()  { echo -e "\e[31m== failure: $@\e[0m"; }

list_tests()   { find "$tests_dir" -wholename "*$exp*" -name '*.json'; }
list_passing() { cat "$expected_passing"; }
list_failing() { list_tests | grep -Fvxf "$expected_passing" -; }

pretty_diff() {
    if type colordiff >/dev/null 2>&1; then
        colordiff -u "$@"
    else
        diff -u "$@"
    fi
}

# Reads a list of json test files from stdin, and runs them
run_tests() {
    local test_file test_fail_count=0
    while read test_file; do
        let test_count="$test_count + 1"
        local output_differs=false
        progress "running: $test_file..."
        pretty_diff \
            --label expected <(cat "$output_file" | lint_krun) \
            --label actual   <(krun --debug --directory k/ "$test_file" | lint_krun) \
            || output_differs=true
        if $output_differs; then
            failure "$test_file"
            let test_fail_count="$test_fail_count + 1"
        else
            success "$test_file"
        fi
        progress "failed: $test_fail_count / $test_count"
    done
    return $test_fail_count
}

filter_tests() {
    local command=( exit 1 )
    case $# in
    0) cat;       return ;;
    1) grep "$1"; return ;;
    *) cat > /dev/null;
       echo >&2 "Too many expressions";
       ;;
    esac
}

run_ktest() {
    progress "running ktest ..."

    pushd k
    ktest ../tests/config.xml
    popd
}

lint_krun() {
    # Format, &gt; entity > and make each K task start on a new line
    xmllint -format - | sed -e 's/&gt;/>/g'  -e 's/~>/\n   ~>/g'
}

run_krun() {
    run_make all
    while read test_file; do
        progress "running: $test_file"
        krun --debug --directory k/ "$test_file" | lint_krun
    done
}

have_tangle=true
check_for_tangle() {
    type pandoc-tangle >/dev/null 2>&1  || {
        have_tangle=false
        echo -e >&2 "Warning: pandoc-tangle not installed."  \
                   "Ignoring changes in markdown files\n"
    }
}

check_for_tangle
run_make() {
    local make_opts=
    $have_tangle || make_opts="--assume-old ethereum.md --assume-old evm.md \
                               --assume-old data.md --assume-old krypto.md"
    make -s $make_opts $@
}

usage() {
    echo "
    usage:
       $0                       Build the definitions and kompile them
       $0 defn                  Only detangle the definitions

       $0 passing <regx>        Run known passing tests
       $0 failing <regx>        Run tests who's results we're not sure of
       $0 test    <regx>        Run passing and unknown tests

                                These tests are filtered by <regex>

       $0 list-tests   <regx>   Run passing and failing tests
       $0 list-failing <regx>   Run failing tests
       $0 list-passing <regx>   Run passing tests


       $0 krun <arg>            Same as test, but pretty print output instead of checking it
"
}

test_pipe_line() {
    local list=$1; shift
    local do_run=$1; shift;

    run_make all
    $list | filter_tests "$@" | $do_run; exit
}

run_debug() {
    run_make all
    file=$(test_pipe_line list_tests cat "$@" | head -n 1)
    krun --debugger --directory k "$file"
    exit
}

[[ "$#" == '0' ]] && set build
while [[ "$#" -gt '0' ]]; do
    run_command="$1" && shift
    case "$run_command" in
        build)        run_make build ;;
        defn)         run_make defn ;;

        passing)      test_pipe_line list_passing run_tests "$@";;
        failing)      test_pipe_line list_failing run_tests "$@";;
        test)         test_pipe_line list_tests   run_tests "$@";;

        krun)         test_pipe_line list_tests   run_krun  "$@";;

        list-tests)   test_pipe_line list_tests   cat       "$@";;
        list-passing) test_pipe_line list_passing cat       "$@";;
        list-failing) test_pipe_line list_failing cat       "$@";;

        debug)        run_debug "$@"                            ;;

        ktest)        run_ktest ;;
        *)            usage; exit 1;;
    esac
done
